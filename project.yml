title: "Coref model wrapped for use in spaCy."
description: >
  This project wraps an existing PyTorch model for use in spaCy.

vars:
  config_name: bert_small
  annotations: assets/conll2012.tar.gz
  gpu_id: 0
  seg_len: 128 # max token length for bert segments
  train_file: assets/train.english.v4_gold_conll
  trained_model: blarg
  ontonotes: /mnt/data/ontonotes

directories: ["data", "data/conll-2012", "data/bert_small"]

assets:
  - dest: "assets/conll2012.tar.gz"
    url: "gs://galaxy-state/conll2012-coref/conll2012-coref.tar.gz"
    description: "CoNLL Annotations"

workflows:
  all_gpu:
    - data
    - preprocess
    - train_gpu
    - evaluate

commands:
  - name: "data"
    help: "Rehydrate the data using OntoNotes"
    script: 
      - tar xvzf assets/conll2012.tar.gz -C assets/
      # untar the individual files
      # TODO package the data in one tar...
      - tar xvzf assets/conll2012-coref/conll-2012-development.v4.tar.gz -C assets/
      - tar xvzf assets/conll2012-coref/conll-2012-scripts.v3.tar.gz -C assets/
      - tar xvzf assets/conll2012-coref/conll-2012-test-key.tar.gz -C assets/
      - tar xvzf assets/conll2012-coref/conll-2012-test-official.v9.tar.gz -C assets/
      - tar xvzf assets/conll2012-coref/conll-2012-train.v4.tar.gz -C assets/
      - tar xvzf assets/conll2012-coref/reference-coreference-scorers.v8.01.tar.gz -C assets/
      - rm -r assets/conll2012-coref # no longer needed

      # fix script issues
      # For the shell script, be sure to use python2.
      - "sed -i 's:python:python2:' assets/conll-2012/v3/scripts/skeleton2conll.sh"
      # In the Python, change the exception syntax that doesn't work in 2.7.
      - "sed -i '392s:,: as :' assets/conll-2012/v3/scripts/skeleton2conll.py"

      # rehydrate data
      # XXX note this can take 20m
      - "bash assets/conll-2012/v3/scripts/skeleton2conll.sh -D ${vars.ontonotes}/data/files/data assets/conll-2012"
      # This model expects all the data to be in single files, so prep that
      - "rm -f assets/*._gold_conll"
      - cat assets/conll-2012/v4/data/development/data/english/annotations/*/*/*/*.v4_gold_conll >> assets/dev.english.v4_gold_conll
      - cat assets/conll-2012/v4/data/train/data/english/annotations/*/*/*/*.v4_gold_conll >> assets/train.english.v4_gold_conll
      - cat assets/conll-2012/v4/data/test/data/english/annotations/*/*/*/*.v4_gold_conll >> assets/test.english.v4_gold_conll
    deps:
      - ${vars.ontonotes}
      - ${vars.annotations}
    outputs:
      - ${vars.train_file}

  - name: "preprocess"
    help: "Run the old prepreprocess script, which depends on seg_len."
    script:
      # This takes about a minute
      - "python preprocess.py --input_dir assets --output_dir assets --seg_len ${vars.seg_len}"

  - name: "train_gpu"
    help: "Train the Coref model using a Transformer"
    script:
      - "python run.py ${vars.config_name} ${vars.gpu_id}"
    deps:
      - ${vars.train_file}
    outputs:
      - ${vars.trained_model}

  - name: "evaluate"
    help: "Evaluate the model on the test data"
    script:
      - "python evaluate.py ${vars.config_name} ${vars.trained_model} ${vars.gpu_id}"

